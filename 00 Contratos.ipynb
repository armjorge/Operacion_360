{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Orquestador de ventas 360: resumen\n",
    "\n",
    "## Input\n",
    "1. Excel de demanda desagregada: con esta información se genera lista de claves y máximos. \n",
    "## Output\n",
    "1. PDF's con nombre estructurado en folder específico. \n",
    "2. Base de datos con información de los contratos y convenios modificatorios generados con el string. \n",
    "\n",
    "## Notas\n",
    "Diseño esto para, partiendo de la demanda desagregada: \n",
    "- Capturar contratos\n",
    "- Descargar xlsx de sistemas SAI, CAMUNDA, SAGI, ZOHO y PISP. \n",
    "- Consultar exceles internos\n",
    "- Organizar las órdenes descargadas\n",
    "- Generar los pickle de las órdenes\n",
    "Todo lo anterior es la información mínima indispensable para poder generar información de ventas, que será la referencia interna sobre la que desplegaremos el alimentado de reportes y la generación de reglas para dar retro al usuario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Importa librerías y carpetas con funciones\n",
    "import sys\n",
    "import os\n",
    "import yaml\n",
    "import pandas as pd\n",
    "import glob\n",
    "# Define the root and script directory\n",
    "folder_root = os.getcwd()  # Get current directory (where Orquestación.ipynb is)\n",
    "script_folder = os.path.join(folder_root, \"Scripts\")  # Path to 'Scripts'\n",
    "# Ensure the script folder is added to sys.path\n",
    "if script_folder not in sys.path:\n",
    "    sys.path.append(script_folder)\n",
    "contratos_library_scripts = os.path.join(script_folder, \"Libreria_contratos\")\n",
    "if contratos_library_scripts not in sys.path:\n",
    "    sys.path.append(contratos_library_scripts)\n",
    "\n",
    "sanciones_folder = os.path.join(script_folder, \"Libreria_SancionesIMSSB\")\n",
    "if sanciones_folder not in sys.path:\n",
    "    sys.path.append(sanciones_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Cargar librerías internas\n",
    "from folders_files_open import create_directory_if_not_exists\n",
    "from STEP_C_PDFhandling import STEP_C_read_PDF_from_source\n",
    "from dataframes_generation import create_dataframe #(extension, dataframe_name, columns, output_folder)\n",
    "# Generador de carpetas\n",
    "from folders_files_open import create_directory_if_not_exists\n",
    "# Administración de contratos:\n",
    "from administracion_de_contratos import administracion_de_contratos\n",
    "from sanciones_IMSSB_processing import print_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Cargar los folders requeridos. \n",
    "working_folder = desagregadas_folder = os.path.join(folder_root, \"Implementación\")\n",
    "desagregadas_folder = os.path.join(folder_root, \"Implementación\", \"Desagregadas\")\n",
    "create_directory_if_not_exists(working_folder)\n",
    "create_directory_if_not_exists(desagregadas_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "# Procesa inputs\n",
    "Las siguiente será la estructura de la carpeta con la información."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "### (1) Carga y (2) limpia demanda desagregada\n",
    "En caso de que no tengas aún demanda desagregada por procedimiento ejecuta los siguientes pasos. \n",
    "El objetivo es generar un dataframe estandarizado con Institución, piezas, procedimiento, y precio. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Seleccionar el archivo XLSX de la carpeta para procesar.\n",
    "XLSX_file_list = glob.glob(os.path.join(desagregadas_folder, \"*.xlsx\"))\n",
    "XLSX_file_list.sort()\n",
    "print(f\"Found {len(XLSX_file_list)} files:\")\n",
    "for f in XLSX_file_list:\n",
    "    print(f\"\\t {os.path.basename(f)}\")\n",
    "\n",
    "# prompt until a valid filename is entered\n",
    "while True:\n",
    "    XLSX_input = input(\"Ingresa el excel de la demanda desagregada:\")\n",
    "    # compare against basenames\n",
    "    basenames = [os.path.basename(f) for f in XLSX_file_list]\n",
    "    if XLSX_input in basenames:\n",
    "        selected_path = os.path.join(desagregadas_folder, XLSX_input)\n",
    "        # Using os.path\n",
    "        parts    = os.path.normpath(selected_path).split(os.sep)\n",
    "        folder1, folder2, fname = parts[-3], parts[-2], parts[-1]\n",
    "        print(f\"✅ Archivo seleccionado: {folder1}/{folder2}/{fname}\")\n",
    "        break\n",
    "    else:\n",
    "        print(\"❌ Selección no válida, elije un archivo de la lista. \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Selecciona la hoja e imprime las columnas\n",
    "# 1. load the workbook and list sheets\n",
    "xls = pd.ExcelFile(selected_path)\n",
    "sheets = xls.sheet_names\n",
    "print(\"Available sheets:\")\n",
    "for name in sheets:\n",
    "    print(\" •\", name)\n",
    "\n",
    "# 2. prompt until a valid sheet is chosen\n",
    "while True:\n",
    "    selected_sheet = input(\"Select a sheet by name: \")\n",
    "    if selected_sheet in sheets:\n",
    "        break\n",
    "    print(\"❌ Invalid sheet. Please choose one from the list above.\")\n",
    "\n",
    "# 3. read that sheet and print file path + its columns\n",
    "df_input_xlsx = pd.read_excel(selected_path, sheet_name=selected_sheet)\n",
    "print(f\"✅ {XLSX_input} — Columnas:\", )\n",
    "print_columns(list(df_input_xlsx.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Genera un dataframe con columnas adecuadas\n",
    "from PROCESA_DESAGREGADA_input import standarized_dataframe_generation\n",
    "standarized_base_columns = [\"Institución\", \"Procedimiento\", \"Clave\", \"Descripción\", \"Precio\", \"Piezas\"]\n",
    "raw_input_excel_columns = list(df_input_xlsx.columns)\n",
    "#print_columns(list(raw_input_excel_columns.columns), n_cols=3)\n",
    "\n",
    "df_clean = standarized_dataframe_generation(df_input_xlsx, standarized_base_columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "### (3) Transformar demanda desagregada\n",
    "Con el dataframe adecuadamente formateado, podemos hacer la agrupación por institución y clave, si se confirma que es lo esperado se exporta a pickle. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Agregamos por institución y procedemos a guardar el pickle. \n",
    "from desagregada_to_pickle import save_to_pickle\n",
    "#print(df_clean.columns)\n",
    "#print(df_clean.info())\n",
    "df_grouped = (\n",
    "    df_clean\n",
    "    .groupby(['Institución','Clave'], as_index=False)\n",
    "    .agg(\n",
    "        Piezas        = ('Piezas',       'sum'),\n",
    "        Procedimiento = ('Procedimiento','first'),\n",
    "        Descripción   = ('Descripción',  'first'),\n",
    "        Precio        = ('Precio',       'first')\n",
    "    )\n",
    ")\n",
    "#print(df_grouped.columns)\n",
    "#print(df_grouped.info())\n",
    "\n",
    "df_grouped.head(20)\n",
    "#print(df_grouped['Procedimiento'].unique())\n",
    "\n",
    "while True:\n",
    "    user_revision = input(\"¿El dataframe es adecuado y está listo para ser guardado? (si/no): \")\n",
    "    respuesta = user_revision.strip().lower()\n",
    "\n",
    "    if respuesta == 'si':\n",
    "        save_to_pickle(df_grouped, desagregadas_folder)\n",
    "        break\n",
    "\n",
    "    elif respuesta == 'no':\n",
    "        print(\"Repite los pasos hasta que estés seguro.\")\n",
    "\n",
    "    else:\n",
    "        print(\"Respuesta no válida. Por favor, responde 'si' o 'no'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "# Administrador de contratos\n",
    "Aquí empieza todo, la demanda desagregada nos da una lista de instituciones, sus piezas máximas y mínimas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "## Elije el procedimiento\n",
    "En esta sección definimos a qué procedimiento corresponde el contrato que vamos a cargar. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carga la demanda desagregada que aplique\n",
    "from desagregada_to_pickle import load_pickles\n",
    "\n",
    "df_proccedure, procedimiento = load_pickles(desagregadas_folder)\n",
    "df_proccedure.info()\n",
    "df_proccedure.sample(4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "## Capturar contrato - Exportar base de contratos\n",
    "1) Captura de contrato: te va haciendo preguntas hasta que tienes un PDF con la leyenda que necesitamos en su cuerpo.\n",
    "2) Extrae la información de los diccionarios del PDF y genera un archivo .pickle con la información.\n",
    "3) Exporta pickle a excel para consulta de los usuarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from folders_files_open import create_directory_if_not_exists\n",
    "from desagregada_to_pickle import base_procedimiento_pickle\n",
    "Columnas = ['Institución', 'Procedimiento', 'Contrato', 'Fecha Inicio', 'Fecha Fin', 'Productos y precio', 'Total', 'Nombre del archivo', 'Estatus', 'Convenio modificatorio', 'Objeto del convenio']\n",
    "print(procedimiento)\n",
    "Folder_procedimiento = os.path.join(folder_root, \"Implementación\", \"Contratos\", f\"{procedimiento}\")\n",
    "create_directory_if_not_exists(Folder_procedimiento)\n",
    "base_procedimiento = base_procedimiento_pickle(Folder_procedimiento, procedimiento, Columnas) \n",
    "print(f\"\\nprocedimiento:{procedimiento}\")\n",
    "\n",
    "# Capturar un nuevo contato\n",
    "#administracion_de_contratos(data_warehouse, working_folder, libreria_contratos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "from STEP_A_orchestration import STEP_A_orchestration\n",
    "STEP_A_orchestration(df_proccedure, procedimiento, Folder_procedimiento)\n",
    "print(base_procedimiento.head(1))\n",
    "#STEP_C_read_PDF_from_source(libreria_contratos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Eseotres",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
